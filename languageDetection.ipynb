{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f5e831f-e052-46a5-b3d0-804226bf6d35",
   "metadata": {},
   "source": [
    "## LANGUAGE DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7514ff5-0bd7-46ea-b701-de4b20e5e4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text  language\n",
      "0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
      "1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
      "2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
      "3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
      "4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
      "5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
      "6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
      "7  müller mox figura centralis circulorum doctoru...     Latin\n",
      "8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
      "9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese\n"
     ]
    }
   ],
   "source": [
    "#IMPORT OF PYTHON LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f07c5b8-ddb4-4f38-8ff2-c6abfd7cce21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "language    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CHECK IF DATA IS NULL OR NOT\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c54185f5-8cbb-4613-a115-648b801ed29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indonesian    1000\n",
       "Hindi         1000\n",
       "Dutch         1000\n",
       "Pushto        1000\n",
       "English       1000\n",
       "Persian       1000\n",
       "Korean        1000\n",
       "Portugese     1000\n",
       "Russian       1000\n",
       "Spanish       1000\n",
       "Japanese      1000\n",
       "Turkish       1000\n",
       "Tamil         1000\n",
       "French        1000\n",
       "Swedish       1000\n",
       "Latin         1000\n",
       "Chinese       1000\n",
       "Urdu          1000\n",
       "Thai          1000\n",
       "Romanian      1000\n",
       "Estonian      1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lANGUAGES PRESENT IN THE DATASET\n",
    "data[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07941c3-f0e0-4afa-a701-8223f9d92ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE DETECTION MODEL\n",
    "# We will split the data into training and test sets\n",
    "x = np.array(data[\"Text\"])\n",
    "y = np.array(data[\"language\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1ea139-fb0f-486d-b1c9-1fabfbf8ec1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.953168044077135"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This problem is of multiclass classification, so we will use *Multinomial Naive Bayes* algorithm to train the language detection model as this algorithm always performs very well on the problems based on multiclass classification\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eac4074e-dce3-451e-b5ce-6230fda0f97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a Text:  hey i am a new language\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English']\n"
     ]
    }
   ],
   "source": [
    "#We can now use this model to detect the language of a text by taking a user input\n",
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f59788-bfc0-4aac-87b5-d36f4a68c5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
